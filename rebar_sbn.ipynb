{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of REBAR (https://arxiv.org/abs/1703.07370), a low-variance, unbiased gradient estimator for discrete latent variable models. This notebook is focused on the generative modeling experiments on the MNIST and Omniglot datasets from Section 5.2.1.\n",
    "\n",
    "The problem being solved is $\\text{max} \\hspace{5px} \\mathbb{E} [f(b, \\theta) | p(b) ]$, $b$ ~ Bernoulli($\\theta$).\n",
    "\n",
    "For generative modeling, the objective is to maximize a single-sample variational lower bound on the log-likelihood. There are two networks, one to model $q(b|x,\\theta)$ and one to model $p(x,b|\\theta)$. The former is the variational distribution and the latter is the joint probability distribution over the data and latent stochastic variables $b$.\n",
    "\n",
    "The **ELBO**, or evidence lower bound which we seek to maximize, is: \n",
    "\n",
    "$$\n",
    "\\log p(x \\vert \\theta) \\geq \\mathbb{E}_{q(b \\vert x,\\theta)} [ \\log p(x,b\\vert\\theta) - \\log q(b \\vert x,\\theta)]\n",
    "$$\n",
    "\n",
    "In practice, the Q-network has its own set of parameters $\\phi$ and the generator network $P$ has its own parameters $\\theta$.\n",
    "\n",
    "I'll refer to the learning signal $\\log p(x,b\\vert\\theta) - \\log q(b \\vert x,\\theta)$ as $l(x,b)$ for shorthand.\n",
    "\n",
    "The following is an implementation of a Sigmoid Belief Network (SBN) with REBAR gradient updates. I tried to follow the [author's TensorFlow implementation](https://github.com/tensorflow/models/blob/master/research/rebar/rebar.py) closely for correctness; there are a lot of computational statistics stuff going on that need to be implemented carefully.\n",
    "\n",
    "For an in-depth treatment on SBNs, see [this paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.63.1777&rep=rep1&type=pdf) by R. Neal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're just going to focus on the nonlinear SBN REBAR model.\n",
    "The model is pretty complex, so I'll implement them as separate modules and try to explain them\n",
    "one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import grad\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import rebar.datasets\n",
    "\n",
    "import rebar.util as U\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some global parameters we'll need later\n",
    "hparams = {\n",
    "    'model': 'SBNGumbel',\n",
    "    'learning_rate':3e-4,\n",
    "    'n_hidden':200,\n",
    "    'n_input':784,\n",
    "    'temperature':0.5,\n",
    "    'batch_size':24,\n",
    "    'task':'sbn',\n",
    "    'n_layers': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define samplers for producing the \"hard\" and \"soft\" reparameterized samples needed for computing the REBAR gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample(log_alpha, u, layer, uniform_samples_v, _):\n",
    "    \"\"\"Returns sampled random variables parameterized by log_alpha.\"\"\"\n",
    "    # Generate tied randomness for later\n",
    "    if layer not in uniform_samples_v:\n",
    "        uniform_samples_v[layer] = u_to_v(log_alpha, u)\n",
    "        \n",
    "    # Sample random variable underlying softmax/argmax\n",
    "    x = log_alpha + U.safe_log_prob(u) - U.safe_log_prob(1 - u)\n",
    "    samples = ((x > 0).float()).detach()\n",
    "\n",
    "    return {\n",
    "        'preactivation': x,\n",
    "        'activation': samples,\n",
    "        'log_param': log_alpha,\n",
    "    }, uniform_samples_v\n",
    "\n",
    "def random_sample_soft(log_alpha, u, layer, uniform_samples_v, temperature=None):\n",
    "    \"\"\"Returns sampled random variables parameterized by log_alpha.\"\"\"\n",
    "\n",
    "    # Sample random variable underlying softmax/argmax\n",
    "    x = log_alpha + U.safe_log_prob(u) - U.safe_log_prob(1 - u)\n",
    "    x /= temperature.view(-1)\n",
    "    y = F.sigmoid(x)\n",
    "\n",
    "    return {\n",
    "        'preactivation': x,\n",
    "        'activation': y,\n",
    "        'log_param': log_alpha\n",
    "    }, uniform_samples_v\n",
    "\n",
    "def random_sample_soft_v(log_alpha, _, layer, uniform_samples_v, temperature=None):\n",
    "    \"\"\"Returns sampled random variables parameterized by log_alpha.\"\"\"\n",
    "    v = uniform_samples[layer]\n",
    "    return random_sample_soft(log_alpha, v, layer, uniform_samples_v, temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next bit, for producing common random numbers, is for variance reduction. [The general idea is easy](https://en.wikipedia.org/wiki/Variance_reduction), but what the authors were doing here is a bit more subtle. According to Appendix G.2, they're correlating u and v to reduce the variance of the gradient by first sampling u and then using that to determine v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Random samplers TODO\n",
    "def u_to_v(log_alpha, u, eps = 1e-8):\n",
    "    \"\"\"Convert u to tied randomness in v.\"\"\"\n",
    "    u_prime = F.sigmoid(-log_alpha)  # g(u') = 0\n",
    "\n",
    "    v_1 = (u - u_prime) / torch.clamp(1 - u_prime, eps, 1)\n",
    "    v_1 = torch.clamp(v_1, 0, 1).detach()\n",
    "    v_1 = v_1*(1 - u_prime) + u_prime\n",
    "    v_0 = u / torch.clamp(u_prime, eps, 1)\n",
    "    v_0 = torch.clamp(v_0, 0, 1).detach()\n",
    "    v_0 = v_0 * u_prime\n",
    "    v = v_1 if(u > u_prime) else v_0\n",
    "    # TODO: add pytorch check\n",
    "    #v = tf.check_numerics(v, 'v sampling is not numerically stable.')\n",
    "    v = v + (-v + u).detach()  # v and u are the same up to numerical errors\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the deterministic mapping we'll use to construct the stochastic layers of the Q- and P-networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformation(nn.Module):\n",
    "    \"\"\"\n",
    "    Deterministic transformation between stochastic layers\n",
    "    \n",
    "        x -> FC -> Tanh -> FC -> Tanh() -> FC -> logQ\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        super(Transformation, self).__init__()\n",
    "        self.h = nn.Sequential(\n",
    "            nn.Linear(n_input, n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_output))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.h(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RecognitionNet is the variational distribution (Q-network) and the GeneratorNet is the joint distribution of the data and latent variables (P-network). It looks like this for an unrolled 2-layer SBN, where Sample is the stochastic layer of Bernoulli units:\n",
    "\n",
    "// Replace with figure?\n",
    "\n",
    "x -> Transformation(x) -> Sample(x) -> Transformation(x) -> Sample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecognitionNet(nn.Module):\n",
    "    \"\"\"\n",
    "    given x values, samples from Q and returns log Q(h|x)\n",
    "    \"\"\"\n",
    "    def __init__(self, mean_xs, uniform_samples, sampler):\n",
    "        super(RecognitionNet, self).__init__()\n",
    "        self.mean_xs = mean_xs\n",
    "        self.uniform_samples = uniform_samples\n",
    "        self.sampler = sampler\n",
    "        self.transforms = nn.ModuleList([Transformation(hparams.n_input,\n",
    "                                        hparams.n_hidden, hparams.n_hidden)\n",
    "                                         for _ in range(hparams.n_layers)])\n",
    "        self.uniform_samples = dict()\n",
    "        self.uniform_samples_v = dict()\n",
    "        # generate randomness\n",
    "        for i in range(self.hparams.n_layers):\n",
    "            self.uniform_samples[i] = Variable(\n",
    "                torch.FloatTensor([self.batch_size, self.hparams.n_hidden]).uniform_(0,1), requires_grad=False)\n",
    "            \n",
    "    def forward(self, x, sampler_=None):\n",
    "        if sampler_ is not None:\n",
    "            sampler = sampler_\n",
    "        else:\n",
    "            sampler = self.sampler\n",
    "        samples = {}\n",
    "        samples[-1] = {'activation': x}\n",
    "        samples[-1] -= mean_xs\n",
    "        samples[-1] = (samples[-1] + 1)/2.\n",
    "        logQ = []\n",
    "        for i,t in enumerate(self.transforms):\n",
    "            input = 2 * samples[i-1]['activation'] - 1.0\n",
    "            logits = t(input)\n",
    "            # expect sampler to return a dictionary with key 'activation'\n",
    "            samples[i], self.uniform_samples_v = sampler(logits, self.uniform_samples[i],\n",
    "                                                         i, self.uniform_samples_v)\n",
    "            logQ.append(U.binary_log_likelihood(samples[-1], logits))  \n",
    "        # logQHard, samples\n",
    "        return logQ, samples\n",
    "\n",
    "class GeneratorNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Returns learning signal and function. Reconstructs the input.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean_xs):\n",
    "        self.transforms = nn.ModuleList()\n",
    "        for i in range(hparams.n_layers):\n",
    "            if i == 0:\n",
    "                n_output = hparams.n_input\n",
    "            else:\n",
    "                n_output = hparams.n_hidden\n",
    "            self.transforms.append(Transformation(hparams.n_input,\n",
    "                                                 hparams.n_hidden, n_output))\n",
    "        self.prior = Variable(torch.zeros(hparams.n_hidden), requires_grad=False)\n",
    "        self.train_bias= -np.log(1./np.clip(mean_xs, 0.001, 0.999)-1.).astype(np.float32)\n",
    "        \n",
    "    def forward(self, x, samples, logQ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            samples: dictionary of sampled latent variables\n",
    "            logQ: list of log q(h_i) terms\n",
    "        \"\"\"\n",
    "        logPPrior = U.binary_log_likelihood(samples[hparams.n_layers-1], self.prior)\n",
    "        for i in reversed(range(hparams.n_layers)):\n",
    "            # Set up the input to the layer\n",
    "            input = 2 * samples[i]['activation'] - 1.0\n",
    "            h = self.transforms[i](input)\n",
    "            if i == 0:\n",
    "                logP = U.binary_log_likelihood(x, h + self.train_bias)\n",
    "            else:\n",
    "                logPPrior += U.binary_log_likelihood(samples[i-1], h)\n",
    "        # Note that logP(x,b) = logP(b|x) + logP(x)\n",
    "        # reinforce_learning_signal (l(x,b)), reinforce_model_grad\n",
    "        return logP + logPPrior - torch.sum(logQ), logP + logPPrior         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can put these modules together inside the SBNRebar module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBNRebar(nn.Module):\n",
    "    def __init__(self, mean_xs):\n",
    "        super(SBN, self).__init__()\n",
    "        self.mean_xs     \n",
    "        # For centering the learning signal, from the NVIL paper (2.3.1) https://arxiv.org/pdf/1402.0030.pdf\n",
    "        # Input dependent baseline that is trained to minimize the MSE with the learning signal\n",
    "        self._baseline = nn.Sequential(\n",
    "           nn.linear(hparams.n_inputs, 100),\n",
    "           nn.Tanh(),\n",
    "           nn.linear(100, 1))\n",
    "        self._temperature = Variable(torch.FloatTensor(hparams.temperature), requires_grad=False)\n",
    "        self._recognition_network = RecognitionNet(mean_xs, random_sample)\n",
    "        self._generator_network = GeneratorNet(mean_xs) \n",
    "                  \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        All of the passes through the Q- and P-networks are here\n",
    "        \"\"\"\n",
    "        # hardELBO is the non-differentiable learning signal, l(x,b)\n",
    "        #\n",
    "        # reinforce_model_grad is the joint distribution of interest p(x,b,\\theta), \n",
    "        #   and the gradient of l(x,b) wrt the P-network params is grad E[logP + logPPrior]  \n",
    "        #   = grad E[reinforce_model_grad]\n",
    "        logQHard, hardSamples = self._recognition_network(x)\n",
    "        hardELBO, reinforce_model_grad = self._generator_network(x, hardSamples, logQHard)\n",
    "        logQHard = torch.sum(logQHard)\n",
    "        baseline = self._baseline(x)\n",
    "        \n",
    "        # compute Gumbel control variate\n",
    "        logQ, softSamples = self._recognition_network(sampler=functools.partial(\n",
    "            random_sample_soft, temperature=self._temperature))\n",
    "        softELBO, _ = self._generator_network(x, softSamples, logQ)\n",
    "        logQ = torch.sum(logQ)\n",
    "        \n",
    "        # compute softELBO_v (same value as softELBO, different grads) :- zsquiggle = g(v, b, \\theta)\n",
    "        # NOTE: !!!Super Tricky!!! Because of the common random numbers (u_to_v), z is distributed as z|b. \n",
    "        # So the reparameterization for p(z|b) is just g(v,b,\\theta) == g(v,\\theta) == log(\\theta/1-\\theta) + log(v/1-v)\n",
    "        # This is why random_sample_soft_v() just calls random_sample_soft()        \n",
    "        logQ_v, softSamples_v = self._recognition_network(sampler=functools.partial(\n",
    "            random_sample_soft_v, temperature=self._temperature))\n",
    "        softELBO_v, _ = self._generator_network(x, softSamples_v, logQ_v)\n",
    "        logQ_v = torch.sum(logQ_v)\n",
    "        \n",
    "        gumbel_cv_learning_signal = softELBO_v.detach()\n",
    "        \n",
    "         # Gumbel CV\n",
    "        gumbel_cv = gumbel_cv_learning_signal * logQHard - softELBO + softELBO_v\n",
    "        \n",
    "        return {\n",
    "            'logQHard': logQHard,\n",
    "            'hardELBO': hardELBO,\n",
    "            'reinforce_model_grad': reinforce_model_grad,\n",
    "            'baseline': baseline,\n",
    "            'gumbel_cv': gumbel_cv\n",
    "        }       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will compute the REBAR gradients using PyTorch's autograd functionality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rebar_gradient(sbn_outs):\n",
    "    nvil_gradient = (sbn_outs['hardELBO'].detach() - sbn_outs['baseline']) * sbn_outs['logQHard'] \n",
    "        + sbn_outs['reinforce_model_grad']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main concepts to understand is the fact that the Concrete relaxation is applied to the discrete RV b ~ Bernoulli($\\theta$), s.t. b = H(z) where H is the heaviside function and z ~ Gumbel.\n",
    "\n",
    "Now, we can initialize a few things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1337\n",
    "torch.manual_seed(random_seed)\n",
    "# hyperparams\n",
    "rebar_eta_z = 0.1\n",
    "rebar_eta_zb = 0.1\n",
    "rebar_lamda=0.5\n",
    "concrete_lamda = 0.5\n",
    "batch_size = 128\n",
    "train_steps = 8000\n",
    "\n",
    "# Initialize three models to compare the REINFORCE, Concrete(0.5), and REBAR estimators\n",
    "reinforce = SimpleBernoulli()\n",
    "concrete = SimpleBernoulli()\n",
    "rebar = SimpleBernoulli()\n",
    "reinforce_opt = optim.Adam(reinforce.parameters(), lr=1e-3)\n",
    "concrete_opt = optim.Adam(concrete.parameters(), lr=1e-3)\n",
    "rebar_opt = optim.Adam(rebar.parameters(), lr=1e-3)\n",
    "mse = nn.MSELoss()\n",
    "# labels\n",
    "targets = Variable(torch.FloatTensor([0.45]).repeat(batch_size), requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the main training loop, where most of the REBAR magic happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforce_loss = []\n",
    "concrete_loss = []\n",
    "rebar_loss = []\n",
    "for i in range(train_steps):\n",
    "    # For each iteration of the loop, we will compute a\n",
    "    # single-sample MC estimate of the gradient\n",
    "    # Get the latest estimate of $\\theta$ copy it to form a minibatch\n",
    "    reinforce_theta = reinforce.forward().repeat(batch_size)\n",
    "    concrete_theta = concrete.forward().repeat(batch_size)\n",
    "    rebar_theta = rebar.forward().repeat(batch_size)\n",
    "    \n",
    "    # sample batch_size pairs of Unif(0,1). You're supposed to couple u,v\n",
    "    # to do the reparameterizations, but we omit that for this toy problem\n",
    "    uv = Variable(torch.FloatTensor(2, batch_size).uniform_(0, 1), requires_grad=False)\n",
    "    u = uv[0] + 1e-9 # for numerical stability\n",
    "    v = uv[1] + 1e-9 # for numerical stability\n",
    "    \n",
    "    ########## First, we'll compute the REINFORCE estimator ##########\n",
    "    \n",
    "    # Lets record where the loss is at currently\n",
    "    discrete_reinforce_preds = torch.bernoulli(reinforce_theta.detach())\n",
    "    reinforce_loss.append(mse(discrete_reinforce_preds, targets).data.numpy())\n",
    "    \n",
    "    # Now, the REINFORCE estimator (Eq. 2 of the paper, beg. of Section 3)\n",
    "    reinforce_z = reparam_pz(u, reinforce_theta)\n",
    "    reinforce_Hz = H(reinforce_z) # this is the non-differentiable reparameterization\n",
    "    # evaluate f\n",
    "    reinforce_f_Hz = (reinforce_Hz - targets) ** 2\n",
    "    # This is  d_log_P(b) / d_$\\theta$\n",
    "    grad_logP = grad(binary_log_likelihood(reinforce_Hz, \\\n",
    "                     torch.log(reinforce_theta)).split(1), reinforce_theta)[0]\n",
    "    \n",
    "    # Apply the Monte-carlo REINFORCE gradient estimator\n",
    "    reinforce_grad_est = (reinforce_f_Hz * grad_logP).mean()\n",
    "    reinforce_opt.zero_grad()\n",
    "    reinforce.theta.grad = reinforce_grad_est\n",
    "    reinforce_opt.step()\n",
    "    \n",
    "    ########## Next up, the Concrete(0.5) estimator ##########\n",
    "    \n",
    "    discrete_concrete_preds = torch.bernoulli(concrete_theta.detach())\n",
    "    concrete_loss.append(mse(discrete_concrete_preds, targets).data.numpy())\n",
    "\n",
    "    # Now, the Concrete(0.5) estimator. We compute the continuous relaxation of\n",
    "    # the reparameterization and use that.. (end of Section 2 of the paper)\n",
    "    concrete_z = reparam_pz(u, concrete_theta)\n",
    "    soft_concrete_z = F.sigmoid(concrete_z / concrete_lamda) + 1e-9\n",
    "    # evaluate f\n",
    "    f_soft_concrete_z = (soft_concrete_z - targets) ** 2\n",
    "    grad_f = grad(f_soft_concrete_z.split(1), concrete_theta)[0]\n",
    "\n",
    "    # Apply the Monte-carlo Concrete gradient estimator\n",
    "    concrete_grad_est = grad_f.mean()\n",
    "    concrete_opt.zero_grad()\n",
    "    concrete.theta.grad = concrete_grad_est\n",
    "    concrete_opt.step()\n",
    "    \n",
    "    ########## Finally, we tie it all together with REBAR ##########\n",
    "    \n",
    "    discrete_rebar_preds = torch.bernoulli(rebar_theta.detach())\n",
    "    rebar_loss.append(mse(discrete_rebar_preds, targets).data.numpy())\n",
    "\n",
    "    # We compute the continuous relaxation of the reparameterization \n",
    "    # as well as the REINFORCE estimator and combine them.\n",
    "\n",
    "    rebar_z = reparam_pz(u, rebar_theta)\n",
    "    # \"hard\" bc this is non-differentiable\n",
    "    hard_concrete_rebar_z = H(rebar_z)\n",
    "    # We also need to compute the reparam for p(z|b) - see the paper\n",
    "    # for explanation of this conditional marginalization as control variate\n",
    "    rebar_zb = reparam_pz_b(v, hard_concrete_rebar_z, rebar_theta)\n",
    "    # \"soft\" relaxations\n",
    "    soft_concrete_rebar_z = F.sigmoid(rebar_z / rebar_lamda) + 1e-9 \n",
    "    soft_concrete_rebar_zb = F.sigmoid(rebar_zb / rebar_lamda) + 1e-9\n",
    "    # evaluate f\n",
    "    f_hard_concrete_rebar_z = (hard_concrete_rebar_z - targets) ** 2\n",
    "    f_soft_concrete_rebar_z = (soft_concrete_rebar_z - targets) ** 2\n",
    "    f_soft_concrete_rebar_zb = (soft_concrete_rebar_zb - targets) ** 2\n",
    "    # compute the necessary derivatives\n",
    "    grad_logP = grad(binary_log_likelihood(hard_concrete_rebar_z, \\\n",
    "                     torch.log(rebar_theta)).split(1), rebar_theta, retain_graph=True)[0]\n",
    "    grad_sc_z = grad(f_soft_concrete_rebar_z.split(1), rebar_theta, retain_graph=True)[0]\n",
    "    grad_sc_zb = grad(f_soft_concrete_rebar_zb.split(1), rebar_theta)[0]\n",
    "    \n",
    "    # Notice how we combine the REINFORCE and concrete estimators\n",
    "    rebar_grad_est = (((f_hard_concrete_rebar_z - rebar_eta_zb * f_soft_concrete_rebar_zb) \\\n",
    "                       * grad_logP) + rebar_eta_zb * grad_sc_z - rebar_eta_zb * grad_sc_zb).mean()\n",
    "    \n",
    "    # Apply the Monte-carlo REBAR gradient estimator\n",
    "    rebar_opt.zero_grad()\n",
    "    rebar.theta.grad = rebar_grad_est\n",
    "    rebar_opt.step()\n",
    "    \n",
    "    if (i+1) % 1000 == 0:\n",
    "        print(\"step: {}\".format(i+1))\n",
    "        print(\"reinforce_loss {}\".format(reinforce_loss[-1]))\n",
    "        print(\"concrete(0.5)_loss {}\".format(concrete_loss[-1]))\n",
    "        print(\"rebar_loss {}\\n\".format(rebar_loss[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the loss per train step to see if we can replicate the results from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "plt.plot(reinforce_loss, 'm', label=\"REINFORCE\", alpha=0.7)\n",
    "plt.plot(concrete_loss, 'r', label=\"Concrete(0.5)\", alpha=0.7)\n",
    "plt.plot(rebar_loss, 'b', label=\"REBAR\", alpha=0.7)\n",
    "plt.title(\"Optimal loss is 0.2025\")\n",
    "plt.xlabel(\"train_steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim(0.2, 0.32)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some final thoughts\n",
    "\n",
    "The variance of the loss in the above plot appears to be significantly greater than in the plots from the paper. Unfortunately, the hyperparameters used for the toy problem were not revealed.. My plot was generated with a batch size of 128. The variance increases a lot with smaller batch sizes. \n",
    "\n",
    "It was mentioned in the paper that the scaling factor, $\\eta$, can be computed by\n",
    "\n",
    "$$\\frac{\\text{Cov}(f,g)}{\\text{Var}(g)}.$$\n",
    "\n",
    "I tried this, but a value of $0.1$ performed better. I may have not been computing $\\eta$ correctly though."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
